{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting music21\n",
      "  Downloading music21-6.3.0.tar.gz (19.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.2 MB 15.5 MB/s eta 0:00:01     |███████████████████████         | 13.8 MB 15.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/anaconda3/lib/python3.7/site-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from music21) (0.14.1)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.7/site-packages (from music21) (8.2.0)\n",
      "Collecting webcolors\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: music21\n",
      "  Building wheel for music21 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for music21: filename=music21-6.3.0-py3-none-any.whl size=21888020 sha256=3c9ddcc8f6233425fa93bba877460ac0b922809bad0d1263512e9f5f9084c063\n",
      "  Stored in directory: /Users/gilmer/Library/Caches/pip/wheels/6a/d0/ae/11a9d9a4052ed2094afc14daf1f5a39569890dedb95be40612\n",
      "Successfully built music21\n",
      "Installing collected packages: webcolors, music21\n",
      "Successfully installed music21-6.3.0 webcolors-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    print(\"Loading Music File:\",file)\n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part):        \n",
    "            notes_to_parse = part.recurse()    \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:      \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path='schubert/'\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why load everything together. Treating it like it's one long song?\n",
    " Then the last note/chord of one song will be thought by the network moreso to be followed by an effectively random note/chord (that of the next song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "unique_notes = list(set(notes_))\n",
    "len(unique_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([187.,  40.,  27.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
       " array([1.0000e+00, 1.4810e+02, 2.9520e+02, 4.4230e+02, 5.8940e+02,\n",
       "        7.3650e+02, 8.8360e+02, 1.0307e+03, 1.1778e+03, 1.3249e+03,\n",
       "        1.4720e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "freq = dict(Counter(notes_))\n",
    "import matplotlib.pyplot as plt\n",
    "no = [count for _,count in freq.items()]\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count >= 50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now prepare new musical files which contain only the top frequent notes\n",
    "new_music = []\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp = []\n",
    "    for note_ in notes:\n",
    "        if (note_ in frequent_notes):\n",
    "            temp.append(note_)\n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the ordering of notes must be even more messed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:  # for a song\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        input_ = note_[i: i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))  # Why not use frequent_notes instead of recalculating\n",
    "                                # I guess the order is different\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
    "# I would have done {note_: number for number note_ in enumerate(unique_x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.2', '0.2.6', '0.3', '0.3.5', '0.3.6', '0.3.7', '0.4', '0.4.7', '0.5', '0.6', '1', '1.3', '1.4', '1.4.7', '1.4.7.10', '1.4.8', '1.5', '1.5.8', '1.6', '1.7', '10', '10.1', '10.1.3', '10.1.5', '10.2', '10.2.5', '10.3', '11', '11.2', '11.2.4', '11.2.6', '11.3', '11.3.6', '11.4', '2', '2.4', '2.4.8', '2.5', '2.5.7', '2.5.9', '2.6', '2.6.9', '2.7', '2.8', '3', '3.6', '3.6.8', '3.6.9', '3.7', '3.7.10', '3.8', '3.9', '4', '4.10', '4.7', '4.7.11', '4.7.9', '4.8', '4.8.11', '4.9', '5', '5.10', '5.11', '5.7', '5.8', '5.8.0', '5.8.11', '5.9', '5.9.0', '6', '6.10', '6.10.1', '6.11', '6.8', '6.9', '6.9.1', '7', '7.0', '7.10', '7.10.0', '7.10.1', '7.10.2', '7.11', '7.11.2', '7.9', '7.9.1', '8', '8.0', '8.0.3', '8.1', '8.11', '8.11.2', '8.11.3', '9', '9.0', '9.0.2', '9.0.4', '9.1', '9.1.4', '9.2', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'B-1', 'B-2', 'B-3', 'B-4', 'B-5', 'B-6', 'B1', 'B2', 'B3', 'B4', 'B5', 'C#2', 'C#3', 'C#4', 'C#5', 'C#6', 'C#7', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'D2', 'D3', 'D4', 'D5', 'D6', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E2', 'E3', 'E4', 'E5', 'E6', 'F#2', 'F#3', 'F#4', 'F#5', 'F#6', 'F2', 'F3', 'F4', 'F5', 'F6', 'G#1', 'G#2', 'G#3', 'G#4', 'G#5', 'G#6', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(frequent_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.2', '0.2.6', '0.3', '0.3.5', '0.3.6', '0.3.7', '0.4', '0.4.7', '0.5', '0.6', '1', '1.3', '1.4', '1.4.7', '1.4.7.10', '1.4.8', '1.5', '1.5.8', '1.6', '1.7', '10', '10.1', '10.1.3', '10.1.5', '10.2', '10.2.5', '10.3', '11', '11.2', '11.2.4', '11.2.6', '11.3', '11.3.6', '11.4', '2', '2.4', '2.4.8', '2.5', '2.5.7', '2.5.9', '2.6', '2.6.9', '2.7', '2.8', '3', '3.6', '3.6.8', '3.6.9', '3.7', '3.7.10', '3.8', '3.9', '4', '4.10', '4.7', '4.7.11', '4.7.9', '4.8', '4.8.11', '4.9', '5', '5.10', '5.11', '5.7', '5.8', '5.8.0', '5.8.11', '5.9', '5.9.0', '6', '6.10', '6.10.1', '6.11', '6.8', '6.9', '6.9.1', '7', '7.0', '7.10', '7.10.0', '7.10.1', '7.10.2', '7.11', '7.11.2', '7.9', '7.9.1', '8', '8.0', '8.0.3', '8.1', '8.11', '8.11.2', '8.11.3', '9', '9.0', '9.0.2', '9.0.4', '9.1', '9.1.4', '9.2', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'B-1', 'B-2', 'B-3', 'B-4', 'B-5', 'B-6', 'B1', 'B2', 'B3', 'B4', 'B5', 'C#2', 'C#3', 'C#4', 'C#5', 'C#6', 'C#7', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'D2', 'D3', 'D4', 'D5', 'D6', 'E-2', 'E-3', 'E-4', 'E-5', 'E-6', 'E2', 'E3', 'E4', 'E5', 'E6', 'F#2', 'F#3', 'F#4', 'F#5', 'F#6', 'F2', 'F3', 'F4', 'F5', 'F6', 'G#1', 'G#2', 'G#3', 'G#4', 'G#5', 'G#6', 'G1', 'G2', 'G3', 'G4', 'G5', 'G6']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare integer sequences for input data\n",
    "x_seq = []\n",
    "for i in x:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq = np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Activation\n",
    "def lstm():\n",
    "    model = Sequential()\n",
    "#    model.add(Input(shape = (no_of_timesteps,)))\n",
    "    model.add(LSTM(128, return_sequences = True))  # How come we dont have to specify input_shape here?\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(len(frequent_notes)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 11]\n",
      "  [117]\n",
      "  [116]\n",
      "  [130]\n",
      "  [ 47]\n",
      "  [124]\n",
      "  [130]\n",
      "  [160]\n",
      "  [130]\n",
      "  [100]\n",
      "  [130]\n",
      "  [ 68]\n",
      "  [100]\n",
      "  [118]\n",
      "  [129]\n",
      "  [  9]\n",
      "  [128]\n",
      "  [  9]\n",
      "  [118]\n",
      "  [ 97]\n",
      "  [  9]\n",
      "  [118]\n",
      "  [100]\n",
      "  [ 97]\n",
      "  [143]\n",
      "  [138]\n",
      "  [ 97]\n",
      "  [ 55]\n",
      "  [ 11]\n",
      "  [118]\n",
      "  [129]\n",
      "  [100]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:659 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1183 call\n        runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1558 lstm_with_backend_selection\n        **params)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2828 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3075 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1315 standard_lstm\n        zero_output_for_mask=zero_output_for_mask)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4214 rnn\n        input_time_zero, tuple(initial_states) + tuple(constants))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1291 step\n        z = K.dot(cell_inputs, kernel)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:1831 dot\n        out = math_ops.matmul(x, y)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3254 matmul\n        a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:5642 mat_mul\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type int64 of argument 'a'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-635f531e2d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrandom_music\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_music\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_music\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_music\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py:659 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1183 call\n        runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1558 lstm_with_backend_selection\n        **params)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2828 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3075 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1315 standard_lstm\n        zero_output_for_mask=zero_output_for_mask)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4214 rnn\n        input_time_zero, tuple(initial_states) + tuple(constants))\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py:1291 step\n        z = K.dot(cell_inputs, kernel)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:1831 dot\n        out = math_ops.matmul(x, y)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3254 matmul\n        a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:5642 mat_mul\n        name=name)\n    /opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type int64 of argument 'a'.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0, len(x_val) - 1)\n",
    "random_music = x_val[ind]\n",
    "\n",
    "model = lstm()\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1, no_of_timesteps, 1) # fixed, LSTM now expects inputs in this shape\n",
    "                                                                \n",
    "    print(random_music)\n",
    "    prob = model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis = 0)\n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    random_music = np.insert(random_music[0], len(random_music[0]), y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x))\n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream\n",
    "def convert_to_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    \n",
    "    for pattern in prediction_output:\n",
    "        if (('.' in pattern) or pattern.isdigit()): # chord\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                cn = int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        else: # note\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music_longer.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now if I wanted to train the model?\n",
    "model = lstm()\n",
    "x_tr = x_tr.reshape(len(x_tr), no_of_timesteps)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint('best_model.h5', monitor = 'val_loss', mode = 'min', save_best_only = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 4.6848 - accuracy: 0.0356\n",
      "Epoch 00001: val_loss improved from inf to 4.58769, saving model to best_model.h5\n",
      "403/403 [==============================] - 82s 204ms/step - loss: 4.6848 - accuracy: 0.0356 - val_loss: 4.5877 - val_accuracy: 0.0413\n",
      "Epoch 2/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 4.5030 - accuracy: 0.0516\n",
      "Epoch 00002: val_loss improved from 4.58769 to 4.44986, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 4.5030 - accuracy: 0.0516 - val_loss: 4.4499 - val_accuracy: 0.0573\n",
      "Epoch 3/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 4.3326 - accuracy: 0.0713\n",
      "Epoch 00003: val_loss improved from 4.44986 to 4.29038, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 4.3326 - accuracy: 0.0713 - val_loss: 4.2904 - val_accuracy: 0.0805\n",
      "Epoch 4/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 4.1451 - accuracy: 0.0961\n",
      "Epoch 00004: val_loss improved from 4.29038 to 4.14541, saving model to best_model.h5\n",
      "403/403 [==============================] - 84s 207ms/step - loss: 4.1451 - accuracy: 0.0961 - val_loss: 4.1454 - val_accuracy: 0.0976\n",
      "Epoch 5/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.9592 - accuracy: 0.1227\n",
      "Epoch 00005: val_loss improved from 4.14541 to 4.00910, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 205ms/step - loss: 3.9592 - accuracy: 0.1227 - val_loss: 4.0091 - val_accuracy: 0.1175\n",
      "Epoch 6/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.7795 - accuracy: 0.1467\n",
      "Epoch 00006: val_loss improved from 4.00910 to 3.89188, saving model to best_model.h5\n",
      "403/403 [==============================] - 82s 204ms/step - loss: 3.7795 - accuracy: 0.1467 - val_loss: 3.8919 - val_accuracy: 0.1369\n",
      "Epoch 7/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.6064 - accuracy: 0.1719\n",
      "Epoch 00007: val_loss improved from 3.89188 to 3.77018, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 3.6064 - accuracy: 0.1719 - val_loss: 3.7702 - val_accuracy: 0.1541\n",
      "Epoch 8/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.4448 - accuracy: 0.1943\n",
      "Epoch 00008: val_loss improved from 3.77018 to 3.69366, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 207ms/step - loss: 3.4448 - accuracy: 0.1943 - val_loss: 3.6937 - val_accuracy: 0.1658\n",
      "Epoch 9/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.2889 - accuracy: 0.2230\n",
      "Epoch 00009: val_loss improved from 3.69366 to 3.62072, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 207ms/step - loss: 3.2889 - accuracy: 0.2230 - val_loss: 3.6207 - val_accuracy: 0.1824\n",
      "Epoch 10/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.1452 - accuracy: 0.2471\n",
      "Epoch 00010: val_loss improved from 3.62072 to 3.54702, saving model to best_model.h5\n",
      "403/403 [==============================] - 84s 208ms/step - loss: 3.1452 - accuracy: 0.2471 - val_loss: 3.5470 - val_accuracy: 0.1944\n",
      "Epoch 11/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 3.0139 - accuracy: 0.2716\n",
      "Epoch 00011: val_loss improved from 3.54702 to 3.49487, saving model to best_model.h5\n",
      "403/403 [==============================] - 87s 215ms/step - loss: 3.0139 - accuracy: 0.2716 - val_loss: 3.4949 - val_accuracy: 0.2090\n",
      "Epoch 12/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.8887 - accuracy: 0.2954\n",
      "Epoch 00012: val_loss improved from 3.49487 to 3.45199, saving model to best_model.h5\n",
      "403/403 [==============================] - 82s 205ms/step - loss: 2.8887 - accuracy: 0.2954 - val_loss: 3.4520 - val_accuracy: 0.2178\n",
      "Epoch 13/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.7767 - accuracy: 0.3161\n",
      "Epoch 00013: val_loss improved from 3.45199 to 3.42064, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 2.7767 - accuracy: 0.3161 - val_loss: 3.4206 - val_accuracy: 0.2224\n",
      "Epoch 14/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.6683 - accuracy: 0.3402\n",
      "Epoch 00014: val_loss improved from 3.42064 to 3.37963, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 2.6683 - accuracy: 0.3402 - val_loss: 3.3796 - val_accuracy: 0.2402\n",
      "Epoch 15/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.5693 - accuracy: 0.3573\n",
      "Epoch 00015: val_loss improved from 3.37963 to 3.34407, saving model to best_model.h5\n",
      "403/403 [==============================] - 83s 206ms/step - loss: 2.5693 - accuracy: 0.3573 - val_loss: 3.3441 - val_accuracy: 0.2455\n",
      "Epoch 16/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.4766 - accuracy: 0.3763\n",
      "Epoch 00016: val_loss improved from 3.34407 to 3.33264, saving model to best_model.h5\n",
      "403/403 [==============================] - 80s 198ms/step - loss: 2.4766 - accuracy: 0.3763 - val_loss: 3.3326 - val_accuracy: 0.2525\n",
      "Epoch 17/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3856 - accuracy: 0.3966\n",
      "Epoch 00017: val_loss improved from 3.33264 to 3.31840, saving model to best_model.h5\n",
      "403/403 [==============================] - 79s 196ms/step - loss: 2.3856 - accuracy: 0.3966 - val_loss: 3.3184 - val_accuracy: 0.2600\n",
      "Epoch 18/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.3020 - accuracy: 0.4145\n",
      "Epoch 00018: val_loss improved from 3.31840 to 3.31405, saving model to best_model.h5\n",
      "403/403 [==============================] - 78s 195ms/step - loss: 2.3020 - accuracy: 0.4145 - val_loss: 3.3141 - val_accuracy: 0.2677\n",
      "Epoch 19/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.2213 - accuracy: 0.4343\n",
      "Epoch 00019: val_loss improved from 3.31405 to 3.29094, saving model to best_model.h5\n",
      "403/403 [==============================] - 79s 196ms/step - loss: 2.2213 - accuracy: 0.4343 - val_loss: 3.2909 - val_accuracy: 0.2746\n",
      "Epoch 20/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.1471 - accuracy: 0.4470\n",
      "Epoch 00020: val_loss improved from 3.29094 to 3.27898, saving model to best_model.h5\n",
      "403/403 [==============================] - 78s 192ms/step - loss: 2.1471 - accuracy: 0.4470 - val_loss: 3.2790 - val_accuracy: 0.2811\n",
      "Epoch 21/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.0707 - accuracy: 0.4666\n",
      "Epoch 00021: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 78s 194ms/step - loss: 2.0707 - accuracy: 0.4666 - val_loss: 3.3030 - val_accuracy: 0.2855\n",
      "Epoch 22/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 2.0043 - accuracy: 0.4812\n",
      "Epoch 00022: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 79s 195ms/step - loss: 2.0043 - accuracy: 0.4812 - val_loss: 3.3014 - val_accuracy: 0.2916\n",
      "Epoch 23/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.9360 - accuracy: 0.4936\n",
      "Epoch 00023: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.9360 - accuracy: 0.4936 - val_loss: 3.2991 - val_accuracy: 0.2957\n",
      "Epoch 24/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.8765 - accuracy: 0.5095\n",
      "Epoch 00024: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 78s 194ms/step - loss: 1.8765 - accuracy: 0.5095 - val_loss: 3.3016 - val_accuracy: 0.3041\n",
      "Epoch 25/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.8218 - accuracy: 0.5235\n",
      "Epoch 00025: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 78s 192ms/step - loss: 1.8218 - accuracy: 0.5235 - val_loss: 3.3022 - val_accuracy: 0.3108\n",
      "Epoch 26/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.7581 - accuracy: 0.5394\n",
      "Epoch 00026: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.7581 - accuracy: 0.5394 - val_loss: 3.3507 - val_accuracy: 0.3067\n",
      "Epoch 27/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.7083 - accuracy: 0.5501\n",
      "Epoch 00027: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 190ms/step - loss: 1.7083 - accuracy: 0.5501 - val_loss: 3.3391 - val_accuracy: 0.3135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.6496 - accuracy: 0.5637\n",
      "Epoch 00028: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.6496 - accuracy: 0.5637 - val_loss: 3.3270 - val_accuracy: 0.3247\n",
      "Epoch 29/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.6003 - accuracy: 0.5751\n",
      "Epoch 00029: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 76s 190ms/step - loss: 1.6003 - accuracy: 0.5751 - val_loss: 3.3616 - val_accuracy: 0.3261\n",
      "Epoch 30/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.5534 - accuracy: 0.5891\n",
      "Epoch 00030: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 76s 189ms/step - loss: 1.5534 - accuracy: 0.5891 - val_loss: 3.3711 - val_accuracy: 0.3333\n",
      "Epoch 31/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.5031 - accuracy: 0.6012\n",
      "Epoch 00031: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 76s 189ms/step - loss: 1.5031 - accuracy: 0.6012 - val_loss: 3.3862 - val_accuracy: 0.3406\n",
      "Epoch 32/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.4632 - accuracy: 0.6106\n",
      "Epoch 00032: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.4632 - accuracy: 0.6106 - val_loss: 3.4085 - val_accuracy: 0.3392\n",
      "Epoch 33/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.4091 - accuracy: 0.6246\n",
      "Epoch 00033: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 190ms/step - loss: 1.4091 - accuracy: 0.6246 - val_loss: 3.3988 - val_accuracy: 0.3514\n",
      "Epoch 34/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.3721 - accuracy: 0.6325\n",
      "Epoch 00034: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.3721 - accuracy: 0.6325 - val_loss: 3.4323 - val_accuracy: 0.3452\n",
      "Epoch 35/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.3338 - accuracy: 0.6404\n",
      "Epoch 00035: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 192ms/step - loss: 1.3338 - accuracy: 0.6404 - val_loss: 3.4670 - val_accuracy: 0.3508\n",
      "Epoch 36/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.2864 - accuracy: 0.6518\n",
      "Epoch 00036: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 78s 193ms/step - loss: 1.2864 - accuracy: 0.6518 - val_loss: 3.4975 - val_accuracy: 0.3549\n",
      "Epoch 37/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.2578 - accuracy: 0.6602\n",
      "Epoch 00037: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.2578 - accuracy: 0.6602 - val_loss: 3.5194 - val_accuracy: 0.3594\n",
      "Epoch 38/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.2157 - accuracy: 0.6708\n",
      "Epoch 00038: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 78s 194ms/step - loss: 1.2157 - accuracy: 0.6708 - val_loss: 3.5582 - val_accuracy: 0.3606\n",
      "Epoch 39/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.1687 - accuracy: 0.6847\n",
      "Epoch 00039: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.1687 - accuracy: 0.6847 - val_loss: 3.5979 - val_accuracy: 0.3633\n",
      "Epoch 40/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.1497 - accuracy: 0.6870\n",
      "Epoch 00040: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 190ms/step - loss: 1.1497 - accuracy: 0.6870 - val_loss: 3.6261 - val_accuracy: 0.3657\n",
      "Epoch 41/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.1158 - accuracy: 0.6942\n",
      "Epoch 00041: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 1.1158 - accuracy: 0.6942 - val_loss: 3.6193 - val_accuracy: 0.3802\n",
      "Epoch 42/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.0761 - accuracy: 0.7065\n",
      "Epoch 00042: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 192ms/step - loss: 1.0761 - accuracy: 0.7065 - val_loss: 3.6591 - val_accuracy: 0.3773\n",
      "Epoch 43/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.0604 - accuracy: 0.7091\n",
      "Epoch 00043: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 192ms/step - loss: 1.0604 - accuracy: 0.7091 - val_loss: 3.6801 - val_accuracy: 0.3863\n",
      "Epoch 44/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 1.0156 - accuracy: 0.7235\n",
      "Epoch 00044: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 79s 197ms/step - loss: 1.0156 - accuracy: 0.7235 - val_loss: 3.7322 - val_accuracy: 0.3837\n",
      "Epoch 45/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.9915 - accuracy: 0.7270\n",
      "Epoch 00045: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 0.9915 - accuracy: 0.7270 - val_loss: 3.8004 - val_accuracy: 0.3821\n",
      "Epoch 46/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.9690 - accuracy: 0.7348\n",
      "Epoch 00046: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 0.9690 - accuracy: 0.7348 - val_loss: 3.7716 - val_accuracy: 0.3883\n",
      "Epoch 47/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.9401 - accuracy: 0.7411\n",
      "Epoch 00047: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 190ms/step - loss: 0.9401 - accuracy: 0.7411 - val_loss: 3.8420 - val_accuracy: 0.3907\n",
      "Epoch 48/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.7468\n",
      "Epoch 00048: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 0.9141 - accuracy: 0.7468 - val_loss: 3.8489 - val_accuracy: 0.3973\n",
      "Epoch 49/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.7608\n",
      "Epoch 00049: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 192ms/step - loss: 0.8754 - accuracy: 0.7608 - val_loss: 3.8831 - val_accuracy: 0.3991\n",
      "Epoch 50/50\n",
      "403/403 [==============================] - ETA: 0s - loss: 0.8574 - accuracy: 0.7638\n",
      "Epoch 00050: val_loss did not improve from 3.27898\n",
      "403/403 [==============================] - 77s 191ms/step - loss: 0.8574 - accuracy: 0.7638 - val_loss: 3.9382 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "model = lstm()\n",
    "\n",
    "x_tr = x_tr.reshape(x_tr.shape[0], no_of_timesteps, 1)\n",
    "y_tr = y_tr.reshape(y_tr.shape[0], 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], no_of_timesteps, 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], 1)\n",
    "\n",
    "x_tr = x_tr.astype('float32')\n",
    "y_tr = y_tr.astype('float32')   # This also seems to be necessary now\n",
    "x_val = x_val.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "\n",
    "history = model.fit(x_tr, y_tr, batch_size = 128, epochs = 50, \\\n",
    "                    validation_data = (x_val, y_val), verbose = 1, callbacks = [mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 11.]\n",
      "  [117.]\n",
      "  [116.]\n",
      "  [130.]\n",
      "  [ 47.]\n",
      "  [124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]]]\n",
      "[[[117.]\n",
      "  [116.]\n",
      "  [130.]\n",
      "  [ 47.]\n",
      "  [124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]]]\n",
      "[[[116.]\n",
      "  [130.]\n",
      "  [ 47.]\n",
      "  [124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]]]\n",
      "[[[130.]\n",
      "  [ 47.]\n",
      "  [124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]]]\n",
      "[[[ 47.]\n",
      "  [124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]]]\n",
      "[[[124.]\n",
      "  [130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]\n",
      "  [138.]]]\n",
      "[[[130.]\n",
      "  [160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]\n",
      "  [138.]\n",
      "  [ 97.]]]\n",
      "[[[160.]\n",
      "  [130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 11.]]]\n",
      "[[[130.]\n",
      "  [100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 11.]]]\n",
      "[[[100.]\n",
      "  [130.]\n",
      "  [ 68.]\n",
      "  [100.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [  9.]\n",
      "  [128.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [ 97.]\n",
      "  [  9.]\n",
      "  [118.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [143.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 55.]\n",
      "  [ 11.]\n",
      "  [118.]\n",
      "  [129.]\n",
      "  [100.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 97.]\n",
      "  [129.]\n",
      "  [138.]\n",
      "  [ 97.]\n",
      "  [ 11.]\n",
      "  [ 11.]\n",
      "  [138.]]]\n",
      "[97, 11, 97, 129, 138, 97, 11, 11, 138, 138]\n"
     ]
    }
   ],
   "source": [
    "random_music = x_val[ind]\n",
    "\n",
    "predictions_new = []\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1, no_of_timesteps, 1) # fixed from the above, LSTM expets inputs in shape\n",
    "                                                               # (# samples, time steps, features)\n",
    "    print(random_music)\n",
    "    prob = model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis = 0)\n",
    "    predictions_new.append(y_pred)\n",
    "    \n",
    "    random_music = np.insert(random_music[0], len(random_music[0]), y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_notes_new = [x_int_to_note[i] for i in predictions_new]\n",
    "convert_to_midi(predicted_notes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I listened to this music_new.mid file that I just generated.\n",
    "# It's quite short and boring\n",
    "# To make it longer just increase the loop time. Would be helpful\n",
    "# to have a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_musical_sequence(model, input_sequence, output_length = 10):\n",
    "    predictions = []\n",
    "    for i in range(output_length):\n",
    "        input_sequence = input_sequence.reshape(1, no_of_timesteps, 1) # fixed from the above, LSTM expets inputs in shape\n",
    "                                                               # (# samples, time steps, features)\n",
    "        prob = model.predict(input_sequence)[0]\n",
    "        y_pred = np.argmax(prob, axis = 0)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "        input_sequence = np.insert(input_sequence[0], len(input_sequence[0]), y_pred)\n",
    "        input_sequence = input_sequence[1:]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_music = x_val[ind]\n",
    "predicted_notes_100 = [x_int_to_note[i] for i in generate_musical_sequence(model, random_music, 100)]\n",
    "convert_to_midi(predicted_notes_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
